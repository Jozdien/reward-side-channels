# reward-side-channels

[Primary Reference](https://www.alignmentforum.org/posts/uSdPa9nrSgmXCtdKN/concrete-experiments-in-inner-alignment) - Evan's original experiment description.

[Reference for understanding motivation better](https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks#4_4__Internalization_or_deception_after_extensive_training) - When I read through this, thought something about this seemed relevant to understanding the motivation.

[Colab reference for SpinningUp dependencies](https://colab.research.google.com/github/lcipolina/gymAI/blob/master/0-Gym_Envs_3_spinup_ExperimentGrid.ipynb)

[Code for Decision Transformer in RL](https://github.com/nikhilbarhate99/min-decision-transformer)

[Colab reference for saving and loading checkpoints](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb)